import time
import logging
import numpy as np
import pandas as pd

from dask import config as cfg
from dask import bag as db
from dask import dataframe as dd
from dask.distributed import Client
from pathlib import Path
from typing import Any, Tuple

from soundade.hpc.arguments import DaskArgumentParser
from soundade.hpc.cluster import clusters
from soundade.data.bag import (
    file_path_to_audio_dict,
    valid_audio_file,
    create_file_load_dictionary,
    load_audio_from_path,
    extract_features_from_audio,
    write_wav,
    reformat_for_dataframe,
    power_spectra_from_audio,
    log_features,
    transform_features,
    extract_banded_audio,
    remove_dc_offset,
    high_pass_filter,
    extract_scalar_features_from_audio,
)

logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

cfg.set({
    "distributed.scheduler.worker-ttl": None
})

def acoustic_features(
    files: dd.DataFrame,
    outfile: str | Path,
    segment_duration: float = 60.0,
    frame: int = 0,
    hop: int = 0,
    n_fft: int = 0,
    npartitions: int = None,
    save_preprocessed: bool = False,
    compute: bool = False,
) -> Tuple[dd.DataFrame, dd.Scalar] | pd.DataFrame:
    start_time = time.time()

    log.info("Loading and filtering corrupt audio...")
    log.info(f"Chunking into segments of duration {segment_duration}...")
    b = (
        files.to_bag(format="dict")
        .filter(lambda audio_dict: audio_dict["valid"])
        .map(create_file_load_dictionary, seconds=segment_duration)
        .flatten()
        .map(load_audio_from_path)
        .map(remove_dc_offset)
        .map(high_pass_filter, fcut=300, forder=2, fname='butter', ftype='highpass')
    )
    # log.info(f'Filtered to {len(audio_segment_dicts)} file segments.')
    # log.info(f"Loading and preprocessing segments")
    # b = (
    #     db.from_sequence(audio_segment_dicts, npartitions=npartitions)
    #     .map(load_audio_from_path)
    #     .map(remove_dc_offset)
    #     .map(high_pass_filter, fcut=300, forder=2, fname='butter', ftype='highpass')
    # )

    # if save_preprocessed is not None:
    #     Path(save_preprocessed).mkdir(parents=True, exist_ok=True)
    #     log.info(f'Saving wav files to {save_preprocessed}.')
    #     b.map(write_wav, outpath=save_preprocessed) # .compute()

    log.debug('Extracting acoustic features')

    """
    {
        "file_cid": file cid [string],
        "FEATURE_NAME": 'FEATURE_ARRAY' [for each feature computed]
        "start_time": start time relative to timestamp (seconds) [float]
        "end_time": end time relative to timestamp (seconds) [float]
        "frame_length": frame length in samples [int],
        "hop_length": hop length in samples [int],
        "n_fft": number of samples per fft [int],
    }
    """
    ddf = (
        b.map(extract_features_from_audio, frame_length=frame, hop_length=hop, n_fft=n_fft)
        # # TODO: returned types need formatting
        # .map(log_features, features=['acoustic evenness index', 'root mean square'])
        # .map(transform_features, lambda f: np.log(1.0 - np.array(f)), name='log(1-{f})', features=['temporal entropy'])
        .map(reformat_for_dataframe)
        .flatten()
        .to_dataframe()
    )

    # frames are indexed by string integer on the columns
    metadata = ddf.iloc[:, :ddf.columns.get_loc(str("0"))]
    features = ddf.iloc[:, ddf.columns.get_loc(str("0")):]

    # shift so frames are now rows
    ddf = ddf.melt(
        id_vars=metadata.columns,
        value_vars=features.columns,
        var_name='frame',
        value_name='value'
    )
    # drop any nulls
    ddf = ddf_long.dropna(subset='value')

    if compute:
        df = ddf.compute()
        df.to_parquet(Path(outfile), index=False)
        log.info(f"Time taken for Acoustic Features: {time.time() - start_time}")
        return df

    future: dd.Scalar = ddf.to_parquet(
        Path(outfile),
        version='2.6',
        allow_truncated_timestamps=True,
        write_index=False,
        compute=False,
    )

    log.info(f"Acoustic features queued, will persist to {outfile}")

    return ddf, future

def main(
    infile=None,
    outfile=None,
    cluster=None,
    memory=0,
    cores=0,
    jobs=0,
    queue='general',
    segment_duration: float = 60.0,
    frame: int = 16_000,
    hop: int = 4_000,
    n_fft: int = 1024,
    npartitions=None,
    local: bool = True,
    threads_per_worker: int = 1,
    compute: bool = False,
    debug: bool = False,
    save_preprocessed=None,
    **kwargs: Any,
) -> dd.DataFrame | None:
    """
    Process audio files using the specified parameters.

    Args:
        infile(str, required): Path to a file index generated by 'index_audio' command.
        outfile (str, required): Output file path.
        cluster (str, optional): Name of the cluster to use. 'arc' or 'altair' or None if local==True. Defaults to None.
        memory (int, optional): Memory limit for each worker in GB. Defaults to 32.
        cores (int, optional): Number of CPU cores per worker. Defaults to 8.
        jobs (int, optional): Number of worker jobs to start. Defaults to 12.
        segment_duration (float, optional): Segment duration for audio. Defaults to 60s.
        frame (int, optional): Frame size for feature extraction. Defaults to 16000.
        hop (int, optional): Hop size for feature extraction. Defaults to 4000.
        n_fft (int, optional): Number of FFT points for feature extraction. Defaults to 16000.
        npartitions (int, optional): Number of partitions for Dask DataFrame. Defaults to 2000.
        local (bool, optional): Flag indicating whether to use a local cluster for computation.
        save_preprocessed (str, optional): Directory to save preprocessed data. Defaults to None.
        compute (bool, optional): Flag indicating whether to persist parquet eagerly. Defaults to false.
        debug (bool, optional): Flag indicating whether to run synchronously. Defaults to false.

    Returns:
        dd.DataFrame

    Raises:
        ValueError: If an error occurs during processing.

    Examples:
        >>> main(indir='./data/ecolistening', outfile='./data/processed/ecolistening/features.parquet',
        ...      frame=2048, hop=512, n_fft=1024,
        ...      local=True, save_preprocessed='./data/processed/ecolistening/processed_audio', compute=True)
        <Client: ...
    """
    assert infile is not None
    assert outfile is not None

    if not local:
        cluster = clusters[cluster](
            cores=cores,
            memory=memory,
            queue=queue,
            name=None
        )
        log.info(cluster.job_script())
        cluster.scale(jobs=jobs)
        client = Client(cluster)
    else:
        if debug:
            cfg.set(scheduler='synchronous')

        client = Client(
            n_workers=cores,
            threads_per_worker=threads_per_worker,
            memory_limit=f'{memory}GiB'
        )
        log.info(client)

    acoustic_features(
        dd.read_parquet(infile),
        outfile=outfile,
        segment_duration=segment_duration,
        frame=frame,
        hop=hop,
        n_fft=n_fft,
        save_preprocessed=save_preprocessed,
        npartitions=npartitions,
        compute=compute,
    )

def get_base_parser():
    parser = DaskArgumentParser(
        description='Extract acoustic features from audio files',
        add_help=False,
    )
    parser.add_argument(
        '--segment-duration',
        default=60.0,
        type=float,
        help='Duration for chunking audio segments (defaults to 60s). Specify -1 to use full clip.'
    )
    parser.add_argument(
        '--frame',
        type=int,
        help='Number of audio frames for a feature frame.'
    )
    parser.add_argument(
        '--hop',
        type=int,
        help='Number of audio frames for the hop.'
    )
    parser.add_argument(
        '--n-fft',
        type=int,
        help='Number of audio frames for the n_fft.'
    )
    parser.add_argument(
        '--save-preprocessed',
        default=None,
        help='Save the preprocessed files to directory.'
    )
    parser.add_argument(
        '--compute',
        default=False,
        action='store_true',
        help='Aggregate the dataframe in memory before saving to parquet.'
    )
    parser.add_argument(
        '--debug',
        default=False,
        action='store_true',
        help='Sets single-threaded for debugging.'
    )
    parser.add_argument(
        "--threads-per-worker",
        type=int,
        default=1,
        help="Threads per worker",
    )
    parser.set_defaults(func=main, **{
        'infile': "/data/files_table.parquet",
        'outfile': "/data/recording_acoustic_features.parquet",
        'local': True,
        'threads_per_worker': 1,
        'memory': 0,
        'cores': 1,
        'frame': 2048,
        'hop': 512,
        'n_fft': 2048,
    })
    return parser

def register_subparser(subparsers):
    parser = subparsers.add_parser(
        "acoustic_features",
        help="Extract acoustic features",
        parents=[get_base_parser()],
        add_help=True,
    )

if __name__ == '__main__':
    parser = get_base_parser()
    args = parser.parse_args()
    log.info(args)
    args.func(**vars(args))
