import dask
import datetime as dt
import itertools
import logging
import numpy as np
import os
import pandas as pd
import time

from dask import config as cfg
from dask import bag as db
from dask import dataframe as dd
from dask.distributed import Client
from pathlib import Path
from typing import Any, Tuple

from soundade.hpc.arguments import DaskArgumentParser
from soundade.hpc.cluster import clusters
from soundade.audio.feature.scalar import Features
from soundade.data.bag import (
    create_file_load_dictionary,
    load_audio_from_path,
    log_features,
    transform_features,
    remove_dc_offset,
    high_pass_filter,
    extract_scalar_features_from_audio,
)

logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

def acoustic_features_meta():
    return pd.DataFrame({
        "sr": pd.Series(dtype="int32[pyarrow]"),
        "segment_id": pd.Series(dtype="string[pyarrow]"),
        "segment_idx": pd.Series(dtype="string[pyarrow]"),
        "file_id": pd.Series(dtype="string[pyarrow]"),
        "duration": pd.Series(dtype="float64[pyarrow]"),
        "offset": pd.Series(dtype="float64[pyarrow]"),
        "frame_length": pd.Series(dtype="int32[pyarrow]"),
        "hop_length": pd.Series(dtype="int32[pyarrow]"),
        "n_fft": pd.Series(dtype="int32[pyarrow]"),
        "feature_length": pd.Series(dtype="int32[pyarrow]"),
        **{
            f"{feature.name}": pd.Series(dtype="float64[pyarrow]")
            for feature in Features
        },
        "log acoustic evenness index": pd.Series(dtype="float64[pyarrow]"),
        "log root mean square": pd.Series(dtype="float64[pyarrow]"),
        "log(1-temporal entropy)": pd.Series(dtype="float64[pyarrow]"),
    })

def acoustic_features(
    root_dir: Path,
    files_df: pd.DataFrame,
    outfile: Path,
    segment_duration: float,
    sample_rate: int | None = None,
    frame: int = 0,
    hop: int = 0,
    n_fft: int = 0,
    dc_correction: bool = True,
    high_pass_filter: bool = True,
    npartitions: int = None,
    compute: bool = False,
    **kwargs: Any,
) -> Tuple[dd.DataFrame, dd.Scalar | None] | pd.DataFrame:
    log.info("Setting up acoustic feature extraction pipeline.")
    log.info("Corrupt files will be filtered.")

    b = db.from_sequence(itertools.chain.from_iterable((
        create_file_load_dictionary(audio_dict, root_dir=root_dir, seconds=segment_duration, sr=sample_rate)
        for audio_dict in files_df[files_df["valid"]].to_dict(orient="records")
    )), npartitions=npartitions)

    log.info(f"Partitions after load: {b.npartitions}")
    log.info(f"Loading audio at {sample_rate}Hz in segments of duration {segment_duration}s")

    b = b.map(load_audio_from_path, root_dir=root_dir, sr=sample_rate)

    if dc_correction:
        log.info("Removing DC offset")
        b = b.map(remove_dc_offset)

    if high_pass_filter:
        log.info("Applying highpass filter at 300Hz")
        b = b.map(high_pass_filter, fcut=300, forder=2, fname="butter", ftype="highpass")

    log.info(f"Extracting acoustic features with FFT params {frame=} {hop=} {n_fft=}")
    ddf = (
        b.map(extract_scalar_features_from_audio, frame_length=frame, hop_length=hop, n_fft=n_fft)
        .map(log_features, features=["acoustic evenness index", "root mean square"])
        .map(transform_features, lambda f: np.log(1.0 - np.array(f)), name="log(1-{f})", features=["temporal entropy"])
        .to_dataframe(meta=acoustic_features_meta())
    )

    log.info("Reshaping features dataframe to long form")

    future: dd.Scalar = ddf.to_parquet(
        Path(outfile),
        allow_truncated_timestamps=True,
        write_index=False,
        compute=False,
    )

    log.info(f"Queued acoustic feature extraction. Will persist to {outfile}")

    if compute:
        dask.compute(future)
        return pd.read_parquet(Path(outfile)), None

    return ddf, future

def main(
    root_dir: Path,
    infile: Path,
    outfile: Path,
    cluster: str | None = None,
    memory: int = 0,
    cores: int = 0,
    jobs: int = 0,
    queue: str = "general",
    local: bool = True,
    threads_per_worker: int = 1,
    debug: bool = False,
    **kwargs: Any,
) -> dd.DataFrame | None:
    """
    Process audio files using the specified parameters.

    Args:
        root_dir: Path to the audio root directory
        infile(str, required): Path to a file index generated by 'index_audio' command.
        outfile (str, required): Output file path.
        cluster (str, optional): Name of the cluster to use. 'arc' or 'altair' or None if local==True. Defaults to None.
        memory (int, optional): Memory limit for each worker in GB. Defaults to 32.
        cores (int, optional): Number of CPU cores per worker. Defaults to 8.
        jobs (int, optional): Number of worker jobs to start. Defaults to 12.
        segment_duration (float, optional): Segment duration for audio. Defaults to 60s.
        frame (int, optional): Frame size for feature extraction. Defaults to 16000.
        hop (int, optional): Hop size for feature extraction. Defaults to 4000.
        n_fft (int, optional): Number of FFT points for feature extraction. Defaults to 16000.
        npartitions (int, optional): Number of partitions for Dask DataFrame. Defaults to 2000.
        local (bool, optional): Flag indicating whether to use a local cluster for computation.
        compute (bool, optional): Flag indicating whether to persist parquet eagerly. Defaults to false.
        debug (bool, optional): Flag indicating whether to run synchronously. Defaults to false.

    Returns:
        dd.DataFrame

    Raises:
        ValueError: If an error occurs during processing.

    Examples:
        >>> main(indir='./data/ecolistening', outfile='./data/processed/ecolistening/features.parquet',
        ...      frame=2048, hop=512, n_fft=1024,
        ...      local=True, compute=True)
        <Client: ...
    """
    if not local:
        cluster = clusters[cluster](
            cores=cores,
            memory=memory,
            queue=queue,
            name=None
        )
        log.info(cluster.job_script())
        cluster.scale(jobs=jobs)
        client = Client(cluster)
    else:
        if debug:
            cfg.set(scheduler='synchronous')

        client = Client(
            n_workers=cores,
            threads_per_worker=threads_per_worker,
            memory_limit=f'{memory}GiB'
        )
        log.info(client)

    start_time = time.time()

    _, future = acoustic_features(
        root_dir,
        pd.read_parquet(infile),
        outfile,
        **kwargs,
    )

    if future is not None:
        dask.compute(future)

    log.info(f"Acoustic feature extraction complete")
    log.info(f"Time taken: {str(dt.timedelta(seconds=time.time() - start_time))}")

def get_base_parser():
    parser = DaskArgumentParser(
        description='Extract acoustic features from audio files',
        add_help=False,
    )
    parser.add_argument(
        "--root-dir",
        type=lambda p: Path(p).expanduser(),
        help="Root directory of the audio files (nested folder structure permitted)",
    )
    parser.add_argument(
        '--segment-duration',
        type=float,
        default=60.0,
        help='Duration for chunking audio segments (defaults to 60s). Specify -1 to use full clip.'
    )
    parser.add_argument(
        '--frame',
        type=int,
        help='Number of audio frames for a feature frame.'
    )
    parser.add_argument(
        '--hop',
        type=int,
        help='Number of audio frames for the hop.'
    )
    parser.add_argument(
        '--n-fft',
        type=int,
        help='Number of audio frames for the n_fft.'
    )
    parser.add_argument(
        "--sample-rate",
        type=int,
        help="Audio sample rate for the audio",
    )
    parser.add_argument(
        "--high-pass-filter",
        type=int,
        default=True,
        action="store_true",
        help="Apply a high pass filter",
    )
    parser.add_argument(
        "--dc-correction",
        type=int,
        default=True,
        action="store_true",
        help="Apply DC Correction",
    )
    parser.add_argument(
        '--compute',
        default=True,
        action='store_true',
        help='Aggregate the dataframe in memory before saving to parquet.'
    )
    parser.add_argument(
        '--debug',
        default=False,
        action='store_true',
        help='Sets single-threaded for debugging.'
    )
    parser.add_argument(
        "--threads-per-worker",
        type=int,
        help="Threads per worker",
    )
    parser.set_defaults(func=main, **{
        "infile": "/".join([os.environ.get("DATA_PATH", "/data"), "files_table.parquet"]),
        "outfile": "/".join([os.environ.get("DATA_PATH", "/data"), "recording_acoustic_features_table.parquet"]),
        'local': os.environ.get("LOCAL", True),
        "memory": os.environ.get("MEM_PER_CPU", 0),
        "cores": os.environ.get("CORES", 0),
        "threads_per_worker": os.environ.get("THREADS_PER_WORKER", 1),
        "segment_duration": os.environ.get("SEGMENT_LEN", 60.0),
        "frame": os.environ.get("FRAME", 2_048),
        "hop": os.environ.get("HOP", 512),
        'n_fft': os.environ.get("N_FFT", 2_048),
        "sample_rate": os.environ.get("SAMPLE_RATE", None),
    })
    return parser

def register_subparser(subparsers):
    parser = subparsers.add_parser(
        "acoustic_features",
        help="Extract acoustic features",
        parents=[get_base_parser()],
        add_help=True,
    )

if __name__ == '__main__':
    parser = get_base_parser()
    args = parser.parse_args()
    log.info(args)
    args.func(**vars(args))
